Question 1
Which of the following best describes the role of the generator in a GAN?

Correct Answer: To produce images

Explanation: The generator's primary role in a GAN is to generate data samples (such as images) that are intended to be indistinguishable from real data. It tries to fool the discriminator into classifying its outputs as real.
Incorrect Answers:

To combine images: The generator does not combine images; it creates new ones from random noise.
To critique images: Critiquing images is the role of the discriminator, not the generator.
To evaluate the loss: Evaluating the loss is part of the training process but not the direct role of the generator.
Question 2
In the generator code, what is the purpose of the Reshape layer?

Correct Answer: To reshape the dense layer into a 3D tensor for images

Explanation: The Reshape layer is used to transform the output of a dense (fully connected) layer into a 3D tensor format suitable for representing images, which can then be further processed by convolutional layers.
Incorrect Answers:

To upsample the images: While upsampling is a function in some layers of GANs, Reshape does not upsample; it changes the shape of the tensor.
To critique the images: Critiquing is done by the discriminator.
To normalize the image values: Reshape does not normalize values; normalization is typically done by other layers.
To flatten the images: Flattening is the opposite of reshaping into 3D; it would convert a tensor into a 1D vector.
Question 3
What does the discriminator do in a GAN?

Correct Answer: Evaluates if an image is real or fake

Explanation: The discriminator's job is to evaluate data samples and distinguish between real data from the dataset and fake data generated by the generator.
Incorrect Answers:

Creates images: The generator creates images, not the discriminator.
Enhances image resolution: The discriminator does not enhance resolution; it classifies images as real or fake.
Combines images: The discriminator evaluates images rather than combining them.
Both create and evaluate images: The discriminator only evaluates, not creates images.
Question 4
Which architecture can help address convergence issues in traditional GANs?

Correct Answer: WGAN

Explanation: WGAN (Wasserstein GAN) improves upon traditional GANs by using a different loss function based on the Earth Mover's Distance (or Wasserstein distance), which helps stabilize the training and address convergence issues.
Incorrect Answers:

LSTM, DBN, CNN, RNN: These are other neural network architectures but do not specifically address GAN convergence issues like WGAN does.
Question 5
Why might someone want to use GANs on the CIFAR-10 dataset?

Correct Answer: To generate novel and relevant images to augment the dataset

Explanation: GANs can be used to create new and diverse images that can expand and enrich the existing dataset, which is valuable for training more robust models.
Incorrect Answers:

To delete images from the dataset: GANs do not delete images.
To classify the images in the dataset: Classification is not a direct application of GANs.
To reduce the size of the dataset: GANs typically increase the dataset size by generating more data.
To critique the images in the dataset: GANs generate images; critiquing is done by the discriminator component.
Question 6
Which of the following is NOT a feedback given to the generator during training?

Correct Answer: This image is pixelated

Explanation: Feedback to the generator is typically binary (real or fake) rather than qualitative descriptions like "pixelated."
Incorrect Answers:

This image looks blurry, This image looks like a car, This is a fake image, This is a genuine image: All these are qualitative evaluations, but feedback is generally binary (real or fake). The "fake" or "genuine" classification is part of the feedback loop.
Question 7
Which activation function is used in the final layer of the generator model?

Correct Answer: tanh

Explanation: The tanh activation function scales the output values to range between -1 and 1, which is useful for image generation where pixel values are normalized to this range.
Incorrect Answers:

relu, leakyrelu, softmax, sigmoid: These are valid activation functions but are not typically used in the final layer of the generator for GANs aimed at image generation.
Question 8
In the provided code, why is discriminator.trainable set to False when setting up the combined system?

Correct Answer: To make sure only the generator is trained in this step

Explanation: During the training of the combined model (which involves both generator and discriminator), the discriminator's weights are frozen to ensure that only the generator is updated. This allows the generator to improve its outputs to fool the discriminator.
Incorrect Answers:

None of the given options, To speed up training, To increase discriminator's accuracy, To prevent overfitting: These do not accurately describe the purpose of setting discriminator.trainable to False during generator training.
Question 9
How many images are there in each class of the CIFAR-10 dataset?

Correct Answer: 6000

Explanation: The CIFAR-10 dataset contains 60,000 images divided into 10 classes, with each class containing 6,000 images.
Incorrect Answers:

12000, 15000, 10000, 5000: These do not match the correct number of images per class in CIFAR-10.
Question 10
Which technique can help in dealing with training instability in GANs?

Correct Answer: Gradient clipping

Explanation: Gradient clipping is used to prevent the gradients from growing too large, which can help stabilize the training process in GANs by limiting the size of updates.
Incorrect Answers:

Noise addition, All of the given options, Data augmentation, Dropout: While these techniques can be useful in training models, gradient clipping is specifically effective in addressing instability issues in GANs.
Question 11
What is used to refine the models during training?

Correct Answer: Adam Optimizer

Explanation: The Adam optimizer is commonly used in training GANs because of its efficient handling of sparse gradients and adaptive learning rate capabilities, which help refine models.
Incorrect Answers:

All of the given options, LeakyReLU, Batch Normalization, Conv2D: While these may contribute to the architecture, the Adam optimizer specifically refers to the optimization process.
Question 12
Which challenge refers to the generator producing limited varieties or even the same sample every time?

Correct Answer: Mode Collapse

Explanation: Mode collapse is a common issue in GANs where the generator produces a limited variety of outputs, often replicating the same samples repeatedly.
Incorrect Answers:

All of the given options, Training Instability, Data Augmentation, Convergence Issues: While these are challenges in GAN training, they do not specifically describe the phenomenon of mode collapse.
Question 13
During training, what does the generator use to improve itself?

Correct Answer: Feedback from the discriminator

Explanation: The generator receives feedback from the discriminator about whether its outputs are classified as real or fake, which it uses to improve its ability to produce convincing data.
Incorrect Answers:

CIFAR-10 dataset, Real images, Feedback from the user, Feedback from both the user and the discriminator: The generator's primary feedback source is the discriminator, not real images or direct user feedback.
Question 14
What are the two main components of a GAN?

Correct Answer: Generator & Discriminator

Explanation: A GAN consists of two main components: the generator, which creates data samples, and the discriminator, which evaluates the authenticity of those samples.
Incorrect Answers:

Discriminator & Evaluator, Generator & Evaluator, Discriminator & Sampler, Generator & UpSampler: These pairs do not accurately describe the components of a GAN.
Question 15
In the discriminator's code, which layer helps in reducing the dimensions of the input image?

Correct Answer: Conv2D with strides

Explanation: The Conv2D layer with strides effectively reduces the dimensions of the input image by performing convolution operations with a stride greater than one, which down-samples the input.
Incorrect Answers:

Reshape, UpSampling2D, Dense, BatchNormalization: These layers do not specifically reduce dimensions in the same way as Conv2D with strides does.
